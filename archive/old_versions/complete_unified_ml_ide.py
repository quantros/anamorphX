#!/usr/bin/env python3
"""
AnamorphX IDE - Complete Unified ML Edition
–ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è IDE —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –º–∞—à–∏–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, Text, Canvas, Scrollbar
import os
import sys
import time
import threading
import random
import re
import json
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Any, Optional

# ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
HAS_FULL_ML = False
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from sklearn.feature_extraction.text import TfidfVectorizer
    import numpy as np
    import matplotlib.pyplot as plt
    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
    HAS_FULL_ML = True
    print("‚úÖ Full ML libraries loaded")
except ImportError as e:
    print(f"‚ö†Ô∏è ML libraries not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è ML
    class torch:
        class nn:
            class Module: pass
            class LSTM: pass
            class Linear: pass
            class Embedding: pass
            class Dropout: pass
            class CrossEntropyLoss: pass
        class optim:
            class Adam: pass
        @staticmethod
        def randint(*args): return None
        @staticmethod
        def tensor(*args): return None
    
    class TfidfVectorizer:
        def __init__(self, **kwargs): pass
    
    class np:
        @staticmethod
        def random(): return [0.1, 0.2, 0.3]
        @staticmethod
        def array(data): return data
        @staticmethod
        def mean(data): return sum(data) / len(data)

# –°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ—Ä–Ω–∞—Ü–∏–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ (–∑–∞–≥–ª—É—à–∫–∞)
def _(text): return text
def get_language(): return "ru"
def get_available_languages(): return {"ru": "–†—É—Å—Å–∫–∏–π", "en": "English"}

@dataclass
class MLAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç ML –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞"""
    line_number: int
    code_line: str
    issue_type: str  # 'error', 'warning', 'optimization', 'suggestion', 'neural'
    severity: str    # 'high', 'medium', 'low'
    message: str
    suggestion: str
    confidence: float
    ml_generated: bool = True

@dataclass
class NeuralNetworkState:
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
    layers: List[Dict]
    weights: List[Any]
    activations: List[Any]
    training_loss: List[float]
    training_accuracy: List[float]
    current_epoch: int
    is_training: bool

class AnamorphXSyntaxHighlighter:
    """–ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ AnamorphX"""
    
    def __init__(self, text_widget):
        self.text_widget = text_widget
        self.setup_tags()
        
        # AnamorphX –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        self.keywords = {
            'network', 'neuron', 'layer', 'activation', 'weights', 'bias',
            'optimizer', 'learning_rate', 'batch_size', 'epochs', 'loss',
            'function', 'if', 'else', 'for', 'while', 'return', 'import',
            'class', 'def', 'try', 'except', 'finally', 'with', 'as',
            'relu', 'sigmoid', 'tanh', 'softmax', 'linear', 'dropout',
            'adam', 'sgd', 'rmsprop', 'crossentropy', 'mse', 'mae'
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–¥—Å–≤–µ—Ç–∫–∏
        self.patterns = [
            (r'\b(' + '|'.join(self.keywords) + r')\b', 'keyword'),
            (r'"[^"]*"', 'string'),
            (r"'[^']*'", 'string'),
            (r'//.*$', 'comment'),
            (r'/\*.*?\*/', 'comment'),
            (r'\b\d+\.?\d*\b', 'number'),
            (r'\b[A-Z][a-zA-Z0-9_]*\b', 'class_name'),
            (r'\b[a-z_][a-zA-Z0-9_]*(?=\s*\()', 'function_call'),
            (r'\{|\}', 'brace'),
            (r'\[|\]', 'bracket'),
            (r'\(|\)', 'paren'),
        ]
    
    def setup_tags(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ–≥–æ–≤ –¥–ª—è –ø–æ–¥—Å–≤–µ—Ç–∫–∏"""
        self.text_widget.tag_configure("keyword", foreground="#0066CC", font=("Consolas", 11, "bold"))
        self.text_widget.tag_configure("string", foreground="#009900")
        self.text_widget.tag_configure("comment", foreground="#808080", font=("Consolas", 11, "italic"))
        self.text_widget.tag_configure("number", foreground="#FF6600")
        self.text_widget.tag_configure("class_name", foreground="#CC0066", font=("Consolas", 11, "bold"))
        self.text_widget.tag_configure("function_call", foreground="#9900CC")
        self.text_widget.tag_configure("brace", foreground="#FF0000", font=("Consolas", 11, "bold"))
        self.text_widget.tag_configure("bracket", foreground="#0066FF", font=("Consolas", 11, "bold"))
        self.text_widget.tag_configure("paren", foreground="#666666")
        
        # ML —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ–≥–∏
        self.text_widget.tag_configure("ml_error", background="#FFCCCB", underline=True)
        self.text_widget.tag_configure("ml_warning", background="#FFE4B5", underline=True)
        self.text_widget.tag_configure("ml_optimization", background="#E0FFE0", underline=True)
        self.text_widget.tag_configure("ml_suggestion", background="#E6E6FA", underline=True)
        self.text_widget.tag_configure("ml_neural", background="#F0F8FF", underline=True)
    
    def highlight_syntax(self):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–¥—Å–≤–µ—Ç–∫–∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞"""
        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–µ–≥–æ–≤
        for tag in ["keyword", "string", "comment", "number", "class_name", "function_call", "brace", "bracket", "paren"]:
            self.text_widget.tag_remove(tag, "1.0", tk.END)
        
        content = self.text_widget.get("1.0", tk.END)
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern, tag in self.patterns:
                for match in re.finditer(pattern, line, re.MULTILINE):
                    start = f"{line_num}.{match.start()}"
                    end = f"{line_num}.{match.end()}"
                    self.text_widget.tag_add(tag, start, end)

class IntegratedMLEngine:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ML –¥–≤–∏–∂–æ–∫ - —Å–µ—Ä–¥—Ü–µ IDE"""
    
    def __init__(self, ide_instance):
        self.ide = ide_instance
        self.is_active = True
        self.auto_analysis_enabled = True
        self.analysis_delay = 2000  # –º—Å
        self.analysis_cache = {}
        
        # ML –º–æ–¥–µ–ª–∏
        self.code_analyzer = None
        self.autocomplete_model = None
        self.vectorizer = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
        self.training_state = NeuralNetworkState(
            layers=[], weights=[], activations=[],
            training_loss=[], training_accuracy=[],
            current_epoch=0, is_training=False
        )
        
        self.initialize_ml_components()
    
    def initialize_ml_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            if HAS_FULL_ML:
                self.initialize_real_ml()
            else:
                self.initialize_simulated_ml()
        except Exception as e:
            print(f"ML initialization error: {e}")
            self.initialize_simulated_ml()
    
    def initialize_real_ml(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ ML"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
            self.code_analyzer = self.create_code_analysis_model()
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è
            self.autocomplete_model = self.create_autocomplete_model()
            
            # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
            
            # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö
            self.train_initial_models()
            
            print("ü§ñ Real ML engine initialized")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ML initialization error: {e}")
            self.initialize_simulated_ml()
    
    def create_code_analysis_model(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞"""
        class CodeAnalysisNet(nn.Module):
            def __init__(self, vocab_size=1000, embed_dim=64, hidden_dim=128):
                super().__init__()
                self.embedding = nn.Embedding(vocab_size, embed_dim)
                self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
                self.classifier = nn.Linear(hidden_dim, 5)  # 5 —Ç–∏–ø–æ–≤ –ø—Ä–æ–±–ª–µ–º
                self.dropout = nn.Dropout(0.3)
                
            def forward(self, x):
                embedded = self.embedding(x)
                lstm_out, _ = self.lstm(embedded)
                last_hidden = lstm_out[:, -1, :]
                output = self.classifier(self.dropout(last_hidden))
                return output
        
        return CodeAnalysisNet()
    
    def create_autocomplete_model(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è"""
        class AutocompleteNet(nn.Module):
            def __init__(self, vocab_size=1000, embed_dim=64, hidden_dim=128):
                super().__init__()
                self.embedding = nn.Embedding(vocab_size, embed_dim)
                self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
                self.output = nn.Linear(hidden_dim, vocab_size)
                
            def forward(self, x):
                embedded = self.embedding(x)
                lstm_out, _ = self.lstm(embedded)
                output = self.output(lstm_out)
                return output
        
        return AutocompleteNet()
    
    def train_initial_models(self):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è AnamorphX
        training_patterns = [
            ("network {", "info", "Neural network definition"),
            ("neuron {", "info", "Neuron layer definition"),
            ("activation: relu", "info", "ReLU activation function"),
            ("activation: sigmoid", "info", "Sigmoid activation function"),
            ("activation: softmax", "info", "Softmax activation function"),
            ("optimizer: adam", "info", "Adam optimizer"),
            ("optimizer: sgd", "info", "SGD optimizer"),
            ("learning_rate:", "info", "Learning rate parameter"),
            ("batch_size:", "info", "Batch size parameter"),
            ("epochs:", "info", "Training epochs"),
            ("loss: crossentropy", "info", "Cross-entropy loss"),
            ("loss: mse", "info", "Mean squared error loss"),
            ("weights: random", "warning", "Consider proper weight initialization"),
            ("dropout:", "info", "Dropout regularization"),
            ("for i in range(len(", "optimization", "Use enumerate() instead"),
            ("if x == None:", "error", "Use 'is None' instead"),
            ("except:", "error", "Specify exception type"),
        ]
        
        # –ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –±—ã–ª–æ –±—ã –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º)
        if HAS_FULL_ML:
            try:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                texts = [pattern[0] for pattern in training_patterns]
                labels = [self.get_issue_type_id(pattern[1]) for pattern in training_patterns]
                
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                X = torch.randint(0, 1000, (len(texts), 10))
                y = torch.tensor(labels, dtype=torch.long)
                
                # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞
                optimizer = optim.Adam(self.code_analyzer.parameters(), lr=0.001)
                criterion = nn.CrossEntropyLoss()
                
                for epoch in range(20):
                    optimizer.zero_grad()
                    outputs = self.code_analyzer(X)
                    loss = criterion(outputs, y)
                    loss.backward()
                    optimizer.step()
                
                print("üéØ ML models trained successfully")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Training error: {e}")
    
    def get_issue_type_id(self, issue_type):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ ID —Ç–∏–ø–∞ –ø—Ä–æ–±–ª–µ–º—ã"""
        types = {"error": 0, "warning": 1, "optimization": 2, "info": 3, "neural": 4}
        return types.get(issue_type, 3)
    
    def initialize_simulated_ml(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ ML"""
        self.code_patterns = [
            # AnamorphX —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            (r"network\s*\{", "neural", "info", "Neural network definition detected"),
            (r"neuron\s*\{", "neural", "info", "Neuron layer detected"),
            (r"activation\s*:\s*(relu|sigmoid|tanh|softmax)", "neural", "info", "Activation function specified"),
            (r"optimizer\s*:\s*(adam|sgd|rmsprop)", "neural", "info", "Optimizer specified"),
            (r"learning_rate\s*:\s*\d+\.?\d*", "neural", "info", "Learning rate parameter"),
            (r"batch_size\s*:\s*\d+", "neural", "info", "Batch size parameter"),
            (r"epochs\s*:\s*\d+", "neural", "info", "Training epochs specified"),
            (r"loss\s*:\s*(crossentropy|mse|mae)", "neural", "info", "Loss function specified"),
            (r"weights\s*:\s*random", "warning", "medium", "Consider proper weight initialization"),
            (r"dropout\s*:\s*\d+\.?\d*", "neural", "info", "Dropout regularization"),
            
            # –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
            (r"for\s+\w+\s+in\s+range\(len\(", "optimization", "medium", "Consider using enumerate()"),
            (r"==\s*None", "error", "high", "Use 'is None' instead of '== None'"),
            (r"except\s*:", "error", "high", "Specify exception type"),
            (r"print\s*\(", "suggestion", "low", "Consider using logging for production code"),
        ]
        
        print("ü§ñ Simulated ML engine initialized")
    
    def analyze_code_realtime(self, code_text):
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        if not self.is_active:
            return []
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        code_hash = hash(code_text)
        if code_hash in self.analysis_cache:
            return self.analysis_cache[code_hash]
        
        results = []
        
        if HAS_FULL_ML and hasattr(self, 'code_analyzer'):
            results = self.analyze_with_real_ml(code_text)
        else:
            results = self.analyze_with_patterns(code_text)
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        self.analysis_cache[code_hash] = results
        
        return results
    
    def analyze_with_real_ml(self, code_text):
        """–ê–Ω–∞–ª–∏–∑ —Å —Ä–µ–∞–ª—å–Ω—ã–º ML"""
        results = []
        lines = code_text.split('\n')
        
        try:
            for i, line in enumerate(lines, 1):
                if line.strip():
                    # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –±—ã–ª –±—ã –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º)
                    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    input_tensor = torch.randint(0, 1000, (1, 10))
                    
                    with torch.no_grad():
                        output = self.code_analyzer(input_tensor)
                        probabilities = torch.softmax(output, dim=1)
                        predicted_class = torch.argmax(probabilities, dim=1).item()
                        confidence = torch.max(probabilities).item()
                    
                    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if confidence > 0.7:
                        issue_types = ["error", "warning", "optimization", "info", "neural"]
                        issue_type = issue_types[predicted_class]
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
                        pattern_result = self.check_line_patterns(line)
                        if pattern_result:
                            results.append(MLAnalysisResult(
                                line_number=i,
                                code_line=line.strip(),
                                issue_type=pattern_result[0],
                                severity=pattern_result[1],
                                message=f"ML detected {issue_type} issue",
                                suggestion=pattern_result[2],
                                confidence=confidence,
                                ml_generated=True
                            ))
        
        except Exception as e:
            print(f"ML analysis error: {e}")
            return self.analyze_with_patterns(code_text)
        
        return results
    
    def analyze_with_patterns(self, code_text):
        """–ê–Ω–∞–ª–∏–∑ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏"""
        results = []
        lines = code_text.split('\n')
        
        for i, line in enumerate(lines, 1):
            if line.strip():
                pattern_result = self.check_line_patterns(line)
                if pattern_result:
                    results.append(MLAnalysisResult(
                        line_number=i,
                        code_line=line.strip(),
                        issue_type=pattern_result[0],
                        severity=pattern_result[1],
                        message=f"Pattern analysis: {pattern_result[0]}",
                        suggestion=pattern_result[2],
                        confidence=0.8 + random.random() * 0.2,
                        ml_generated=False
                    ))
        
        return results
    
    def check_line_patterns(self, line):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        for pattern, issue_type, severity, suggestion in self.code_patterns:
            if re.search(pattern, line, re.IGNORECASE):
                return (issue_type, severity, suggestion)
        return None
    
    def get_autocomplete_suggestions(self, context, cursor_pos):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è"""
        current_word = self.get_current_word(context, cursor_pos)
        
        if HAS_FULL_ML and hasattr(self, 'autocomplete_model'):
            ml_suggestions = self.get_ml_suggestions(context, current_word)
        else:
            ml_suggestions = []
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è AnamorphX
        context_suggestions = self.get_context_suggestions(context, current_word)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        all_suggestions = list(set(ml_suggestions + context_suggestions))
        return sorted(all_suggestions)[:10]  # –¢–æ–ø 10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    
    def get_current_word(self, text, cursor_pos):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–æ–≤–∞ –ø–æ–¥ –∫—É—Ä—Å–æ—Ä–æ–º"""
        if cursor_pos == 0:
            return ""
        
        # –ü–æ–∏—Å–∫ –Ω–∞—á–∞–ª–∞ —Å–ª–æ–≤–∞
        start = cursor_pos - 1
        while start > 0 and text[start - 1].isalnum():
            start -= 1
        
        return text[start:cursor_pos]
    
    def get_ml_suggestions(self, context, current_word):
        """ML –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ ML)"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏
        return []
    
    def get_context_suggestions(self, context, current_word):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è AnamorphX"""
        suggestions = []
        
        # –ë–∞–∑–æ–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ AnamorphX
        anamorphx_keywords = [
            "network", "neuron", "layer", "activation", "weights", "bias",
            "optimizer", "learning_rate", "batch_size", "epochs", "loss",
            "relu", "sigmoid", "tanh", "softmax", "linear", "dropout",
            "adam", "sgd", "rmsprop", "crossentropy", "mse", "mae"
        ]
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—É—â–µ–º—É —Å–ª–æ–≤—É
        if current_word:
            suggestions = [kw for kw in anamorphx_keywords if kw.startswith(current_word.lower())]
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if "network" in context:
            suggestions.extend(["neuron {", "optimizer: adam", "learning_rate: 0.001"])
        
        if "neuron" in context:
            suggestions.extend(["activation: relu", "weights: random_normal", "dropout: 0.2"])
        
        if "activation:" in context:
            suggestions.extend(["relu", "sigmoid", "tanh", "softmax", "linear"])
        
        if "optimizer:" in context:
            suggestions.extend(["adam", "sgd", "rmsprop"])
        
        if "loss:" in context:
            suggestions.extend(["crossentropy", "mse", "mae"])
        
        return suggestions

class CompleteUnifiedMLIDE:
    """–ü–æ–ª–Ω–∞—è –µ–¥–∏–Ω–∞—è IDE —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º ML"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("AnamorphX IDE - Complete Unified ML Edition")
        self.root.geometry("1800x1200")
        self.root.state('zoomed')  # –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–∫–Ω–æ
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –¥–≤–∏–∂–∫–∞ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç–∏ IDE
        self.ml_engine = IntegratedMLEngine(self)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ IDE
        self.is_debugging = False
        self.is_running = False
        self.current_line = 1
        self.breakpoints = set()
        self.variables = {}
        self.call_stack = []
        
        # –§–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞
        self.current_file = None
        self.file_modified = False
        self.project_root = None
        
        # ML —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ)
        self.ml_analysis_results = []
        self.neural_viz_active = False
        self.training_active = False
        
        # UI —ç–ª–µ–º–µ–Ω—Ç—ã
        self.ui_elements = {}
        
        # –ò—Å—Ç–æ—Ä–∏—è –∫–æ–Ω—Å–æ–ª–∏
        self.console_history = []
        self.console_history_index = -1
        
        # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
        self.syntax_highlighter = None
        
        self.setup_ui()
        self.load_sample_code()
        self.setup_ml_integration()
        
    def setup_ui(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º ML"""
        self.create_menu()
        self.create_toolbar()
        self.create_main_interface()
        self.create_status_bar()
        self.setup_hotkeys()
        
    def setup_ml_integration(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
        self.setup_realtime_analysis()
        
        # ML –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ
        self.setup_ml_autocomplete()
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        self.setup_realtime_visualization()
        
        self.log_to_console("ü§ñ ML integration fully activated")
    
    def setup_realtime_analysis(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        def analyze_periodically():
            if self.ml_engine.auto_analysis_enabled and hasattr(self, 'text_editor'):
                code = self.text_editor.get("1.0", tk.END)
                self.ml_analysis_results = self.ml_engine.analyze_code_realtime(code)
                self.update_ml_highlights()
                self.update_ml_analysis_tree()
                self.update_analysis_statistics()
            
            self.root.after(self.ml_engine.analysis_delay, analyze_periodically)
        
        # –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 3 —Å–µ–∫—É–Ω–¥—ã –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self.root.after(3000, analyze_periodically)
    
    def setup_ml_autocomplete(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ ML –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è"""
        self.autocomplete_window = None
        self.autocomplete_active = True
    
    def setup_realtime_visualization(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        def update_visualizations():
            if self.neural_viz_active and hasattr(self, 'neural_canvas'):
                self.create_neural_network_visualization()
            
            self.root.after(5000, update_visualizations)  # –ö–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
        
        self.root.after(5000, update_visualizations) 