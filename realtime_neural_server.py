#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß† REAL-TIME AnamorphX Neural Web Server
–ù–ê–°–¢–û–Ø–©–ò–ô –Ω–µ–π—Ä–æ–Ω–Ω—ã–π –≤–µ–±-—Å–µ—Ä–≤–µ—Ä —Å LIVE –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏
"""

import sys
import os
import time
import re
import json
import asyncio
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import threading
import queue
from concurrent.futures import ThreadPoolExecutor
from http.server import HTTPServer, BaseHTTPRequestHandler
from socketserver import ThreadingMixIn
from urllib.parse import urlparse, parse_qs
from datetime import datetime
import uuid

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ UTF-8
import locale
locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')

class NeuralRequestClassifier(nn.Module):
    """–ù–∞—Å—Ç–æ—è—â–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, vocab_size=1000, embedding_dim=64, hidden_dim=128, num_classes=5):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
        self.fc1 = nn.Linear(hidden_dim, 64)
        self.fc2 = nn.Linear(64, num_classes)
        self.dropout = nn.Dropout(0.3)
        
    def forward(self, x):
        embedded = self.embedding(x)
        lstm_out, (hidden, _) = self.lstm(embedded)
        output = self.fc1(hidden[-1])
        output = F.relu(output)
        output = self.dropout(output)
        output = self.fc2(output)
        return F.softmax(output, dim=1)

class RealtimeEventManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Å–æ–±—ã—Ç–∏–π —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏"""
    
    def __init__(self):
        self.clients = set()
        self.event_queue = queue.Queue()
        self.running = True
        
        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–±—ã—Ç–∏–π
        self.event_thread = threading.Thread(target=self._event_broadcaster, daemon=True)
        self.event_thread.start()
    
    def add_client(self, client_id):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"""
        self.clients.add(client_id)
        print(f"üì° –ö–ª–∏–µ–Ω—Ç {client_id} –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ real-time —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º")
    
    def remove_client(self, client_id):
        """–£–¥–∞–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞"""
        self.clients.discard(client_id)
        print(f"üì° –ö–ª–∏–µ–Ω—Ç {client_id} –æ—Ç–∫–ª—é—á–µ–Ω –æ—Ç real-time —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")
    
    def emit_event(self, event_type, data):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–±—ã—Ç–∏—è –≤—Å–µ–º –∫–ª–∏–µ–Ω—Ç–∞–º"""
        event = {
            'type': event_type,
            'timestamp': datetime.now().isoformat(),
            'data': data
        }
        self.event_queue.put(event)
    
    def _event_broadcaster(self):
        """–§–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–±—ã—Ç–∏–π"""
        while self.running:
            try:
                event = self.event_queue.get(timeout=1)
                # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∞ –±—ã –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ WebSocket
                print(f"üì° Broadcasting: {event['type']} to {len(self.clients)} clients")
            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå Event broadcast error: {e}")

class RequestProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é"""
    
    def __init__(self, event_manager):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = NeuralRequestClassifier()
        self.model.to(self.device)
        self.event_manager = event_manager
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        self.vocab = self._build_vocab()
        self.request_classes = ['api', 'health', 'neural', 'admin', 'custom']
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        self._initialize_weights()
        
        print(f"üß† Neural model loaded on {self.device}")
        print(f"üìä Model parameters: {sum(p.numel() for p in self.model.parameters()):,}")
    
    def _build_vocab(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        common_words = [
            'get', 'post', 'api', 'health', 'neural', 'admin', 'status', 'info',
            'data', 'request', 'response', 'server', 'network', 'model', 'predict',
            'train', 'test', 'validate', 'metric', 'loss', 'accuracy', 'error',
            'realtime', 'live', 'stream', 'events', 'websocket'
        ]
        return {word: idx + 1 for idx, word in enumerate(common_words)}
    
    def _initialize_weights(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏"""
        for module in self.model.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                nn.init.zeros_(module.bias)
            elif isinstance(module, nn.LSTM):
                for name, param in module.named_parameters():
                    if 'weight' in name:
                        nn.init.xavier_uniform_(param)
                    elif 'bias' in name:
                        nn.init.zeros_(param)
    
    def encode_request(self, path, method='GET', headers=None):
        """–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        text = f"{method.lower()} {path.lower()}"
        if headers:
            text += " " + " ".join(headers.keys()).lower()
        
        tokens = []
        for word in text.split():
            if word in self.vocab:
                tokens.append(self.vocab[word])
            else:
                tokens.append(0)  # UNK token
        
        # –ü–∞–¥–¥–∏–Ω–≥ –¥–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã
        max_len = 20
        if len(tokens) > max_len:
            tokens = tokens[:max_len]
        else:
            tokens.extend([0] * (max_len - len(tokens)))
        
        return torch.tensor([tokens], dtype=torch.long)
    
    def classify_request(self, path, method='GET', headers=None):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é"""
        start_time = time.time()
        
        with torch.no_grad():
            encoded = self.encode_request(path, method, headers)
            encoded = encoded.to(self.device)
            
            # –ü—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
            output = self.model(encoded)
            predicted_class = torch.argmax(output, dim=1).item()
            confidence = torch.max(output).item()
            
            processing_time = time.time() - start_time
            
            result = {
                'class': self.request_classes[predicted_class],
                'confidence': float(confidence),
                'raw_output': output.cpu().numpy().tolist()[0],
                'processing_time': processing_time
            }
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ real-time —Å–æ–±—ã—Ç–∏—è
            self.event_manager.emit_event('neural_inference', {
                'path': path,
                'method': method,
                'classification': result,
                'timestamp': datetime.now().isoformat()
            })
            
            return result

class ThreadingHTTPServer(ThreadingMixIn, HTTPServer):
    """–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π HTTP —Å–µ—Ä–≤–µ—Ä"""
    daemon_threads = True

class RealtimeNeuralWebServer:
    """REAL-TIME –Ω–µ–π—Ä–æ–Ω–Ω—ã–π –≤–µ–±-—Å–µ—Ä–≤–µ—Ä"""
    
    def __init__(self, anamorph_file="Project/web_server.anamorph"):
        self.anamorph_file = anamorph_file
        self.config = {}
        self.event_manager = RealtimeEventManager()
        self.neural_processor = RequestProcessor(self.event_manager)
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å real-time –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏
        self.stats = {
            'requests_processed': 0,
            'neural_inferences': 0,
            'start_time': time.time(),
            'request_types': {},
            'response_times': [],
            'active_clients': 0,
            'last_inference_time': None,
            'avg_confidence': 0.0
        }
        
        self._load_config()
        
        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats_thread = threading.Thread(target=self._update_stats_loop, daemon=True)
        self.stats_thread.start()
    
    def _load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(self.anamorph_file, 'r', encoding='utf-8') as f:
                code = f.read()
            
            self.config = {
                'host': 'localhost',
                'port': 8080,
                'neural_processing': True,
                'realtime_updates': True
            }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Ä—Ç–∞
            port_match = re.search(r'port[:\s]*(\d+)', code, re.IGNORECASE)
            if port_match:
                self.config['port'] = int(port_match.group(1))
            
            print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.anamorph_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {e}")
    
    def _update_stats_loop(self):
        """–§–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        while True:
            try:
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
                time.sleep(2)
                
                # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if self.stats['response_times']:
                    self.stats['avg_confidence'] = np.mean([
                        getattr(self, '_last_confidences', [0.5])[-10:]
                    ])
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self.event_manager.emit_event('stats_update', {
                    'requests_processed': self.stats['requests_processed'],
                    'neural_inferences': self.stats['neural_inferences'],
                    'uptime': time.time() - self.stats['start_time'],
                    'avg_response_time': np.mean(self.stats['response_times'][-20:]) if self.stats['response_times'] else 0,
                    'active_clients': len(self.event_manager.clients)
                })
                
            except Exception as e:
                print(f"‚ùå Stats update error: {e}")
    
    def process_request_neural(self, path, method, headers, body=None):
        """–ù–µ–π—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å real-time —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏"""
        start_time = time.time()
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
        classification = self.neural_processor.classify_request(path, method, headers)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        response_data = self._generate_neural_response(classification, path, body)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        processing_time = time.time() - start_time
        self.stats['neural_inferences'] += 1
        self.stats['response_times'].append(processing_time)
        self.stats['last_inference_time'] = datetime.now().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if not hasattr(self, '_last_confidences'):
            self._last_confidences = []
        self._last_confidences.append(classification['confidence'])
        if len(self._last_confidences) > 50:
            self._last_confidences = self._last_confidences[-50:]
        
        return response_data, classification, processing_time
    
    def _generate_neural_response(self, classification, path, body):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        request_class = classification['class']
        confidence = classification['confidence']
        
        base_response = {
            'timestamp': datetime.now().isoformat(),
            'neural_classification': classification,
            'processing_method': 'realtime_neural_network',
            'confidence': confidence,
            'path': path,
            'realtime_enabled': True
        }
        
        if request_class == 'api':
            base_response.update({
                'server': 'AnamorphX Real-Time Neural Server',
                'version': '3.0.0',
                'neural_engine': 'PyTorch + Real-Time',
                'model_parameters': sum(p.numel() for p in self.neural_processor.model.parameters()),
                'device': str(self.neural_processor.device),
                'features': ['realtime_neural_processing', 'live_updates', 'pytorch_integration'],
                'active_clients': len(self.event_manager.clients)
            })
        
        elif request_class == 'health':
            uptime = time.time() - self.stats['start_time']
            base_response.update({
                'status': 'realtime_neural_healthy',
                'uptime_seconds': uptime,
                'model_status': 'active_with_realtime',
                'inference_count': self.stats['neural_inferences'],
                'avg_response_time': np.mean(self.stats['response_times'][-100:]) if self.stats['response_times'] else 0,
                'live_clients': len(self.event_manager.clients)
            })
        
        return base_response

class RealtimeNeuralRequestHandler(BaseHTTPRequestHandler):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å real-time –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏"""
    
    def __init__(self, server_instance, *args, **kwargs):
        self.server_instance = server_instance
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        """GET –∑–∞–ø—Ä–æ—Å—ã —Å real-time –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        start_time = time.time()
        parsed_path = urlparse(self.path)
        path = parsed_path.path
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã –¥–ª—è real-time
        if path == '/events':
            self._handle_sse()
            return
        elif path == '/live-stats':
            self._handle_live_stats()
            return
        
        # –ù–µ–π—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        neural_data, classification, processing_time = self.server_instance.process_request_neural(
            path, 'GET', dict(self.headers)
        )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        if path == '/':
            response = self._handle_realtime_index(neural_data, classification)
        elif path == '/api':
            response = self._handle_neural_api(neural_data)
        elif path == '/health':
            response = self._handle_neural_health(neural_data)
        elif path == '/neural':
            response = self._handle_neural_status(neural_data)
        elif path == '/metrics':
            response = self._handle_metrics()
        else:
            response = self._handle_neural_custom(path, neural_data, classification)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total_time = time.time() - start_time
        self.server_instance.stats['requests_processed'] += 1
        self.server_instance.stats['request_types'][path] = self.server_instance.stats['request_types'].get(path, 0) + 1
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å real-time –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        print(f"üß† LIVE GET {path} | Class: {classification['class']} | Confidence: {classification['confidence']:.3f} | Time: {total_time:.3f}s | Clients: {len(self.server_instance.event_manager.clients)}")
        
        self._send_neural_response(response)
    
    def _handle_sse(self):
        """Server-Sent Events –¥–ª—è real-time –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π"""
        client_id = str(uuid.uuid4())
        self.server_instance.event_manager.add_client(client_id)
        
        try:
            self.send_response(200)
            self.send_header('Content-Type', 'text/event-stream')
            self.send_header('Cache-Control', 'no-cache')
            self.send_header('Connection', 'keep-alive')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            welcome_data = {
                'type': 'connected',
                'client_id': client_id,
                'server': 'AnamorphX Real-Time Neural Server',
                'timestamp': datetime.now().isoformat()
            }
            
            self.wfile.write(f"data: {json.dumps(welcome_data)}\n\n".encode('utf-8'))
            self.wfile.flush()
            
            # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–±—ã—Ç–∏–π
            while True:
                try:
                    # –û—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
                    time.sleep(3)
                    
                    stats_data = {
                        'type': 'live_stats',
                        'data': {
                            'requests': self.server_instance.stats['requests_processed'],
                            'inferences': self.server_instance.stats['neural_inferences'],
                            'uptime': time.time() - self.server_instance.stats['start_time'],
                            'clients': len(self.server_instance.event_manager.clients),
                            'avg_response_time': np.mean(self.server_instance.stats['response_times'][-10:]) if self.server_instance.stats['response_times'] else 0
                        },
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    self.wfile.write(f"data: {json.dumps(stats_data)}\n\n".encode('utf-8'))
                    self.wfile.flush()
                    
                except Exception as e:
                    print(f"‚ùå SSE send error: {e}")
                    break
                    
        except Exception as e:
            print(f"‚ùå SSE error: {e}")
        finally:
            self.server_instance.event_manager.remove_client(client_id)
    
    def _handle_live_stats(self):
        """–¢–µ–∫—É—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ JSON"""
        stats = {
            'requests_processed': self.server_instance.stats['requests_processed'],
            'neural_inferences': self.server_instance.stats['neural_inferences'],
            'uptime': time.time() - self.server_instance.stats['start_time'],
            'active_clients': len(self.server_instance.event_manager.clients),
            'avg_response_time': np.mean(self.server_instance.stats['response_times'][-20:]) if self.server_instance.stats['response_times'] else 0,
            'last_inference': self.server_instance.stats.get('last_inference_time'),
            'request_types': dict(self.server_instance.stats['request_types']),
            'timestamp': datetime.now().isoformat()
        }
        
        response = {
            'status': 200,
            'content': json.dumps(stats, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
        
        self._send_neural_response(response)
    
    def _handle_realtime_index(self, neural_data, classification):
        """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å REAL-TIME –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏"""
        confidence = classification['confidence']
        html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üß† Real-Time AnamorphX Neural Server</title>
    <style>
        body {{ font-family: 'SF Pro Display', system-ui; margin: 0; padding: 20px; 
               background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
        .container {{ background: rgba(255,255,255,0.95); padding: 40px; border-radius: 20px; 
                     box-shadow: 0 25px 50px rgba(0,0,0,0.15); }}
        h1 {{ color: #2E7D32; text-align: center; margin-bottom: 30px; }}
        .live-indicator {{ background: linear-gradient(45deg, #4CAF50, #81C784); color: white; 
                          padding: 15px; border-radius: 10px; text-align: center; margin: 20px 0;
                          animation: pulse 2s infinite; }}
        @keyframes pulse {{ 0% {{ opacity: 1; }} 50% {{ opacity: 0.7; }} 100% {{ opacity: 1; }} }}
        .grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        .card {{ background: white; padding: 25px; border-radius: 15px; box-shadow: 0 8px 25px rgba(0,0,0,0.1); }}
        .metric {{ background: #e3f2fd; padding: 12px; margin: 8px 0; border-radius: 8px; 
                  display: flex; justify-content: space-between; }}
        .live-metric {{ background: #e8f5e8; padding: 12px; margin: 8px 0; border-radius: 8px; 
                       display: flex; justify-content: space-between; }}
        .confidence {{ font-size: 1.2em; font-weight: bold; 
                      color: {'#4CAF50' if confidence > 0.7 else '#FF9800' if confidence > 0.4 else '#f44336'}; }}
        .real-time-data {{ border: 2px solid #4CAF50; }}
    </style>
    <script>
        // REAL-TIME –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ Server-Sent Events
        let eventSource;
        
        function startRealTimeUpdates() {{
            eventSource = new EventSource('/events');
            
            eventSource.onmessage = function(event) {{
                const data = JSON.parse(event.data);
                updateLiveStats(data);
            }};
            
            eventSource.onerror = function(event) {{
                console.error('SSE Error:', event);
                setTimeout(startRealTimeUpdates, 5000); // Reconnect after 5 seconds
            }};
        }}
        
        function updateLiveStats(data) {{
            if (data.type === 'live_stats') {{
                document.getElementById('live-requests').textContent = data.data.requests;
                document.getElementById('live-inferences').textContent = data.data.inferences;
                document.getElementById('live-uptime').textContent = Math.floor(data.data.uptime) + 's';
                document.getElementById('live-clients').textContent = data.data.clients;
                document.getElementById('live-response-time').textContent = (data.data.avg_response_time * 1000).toFixed(1) + 'ms';
                document.getElementById('last-update').textContent = new Date().toLocaleTimeString();
            }}
        }}
        
        // –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ fetch –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
        function fetchLiveStats() {{
            fetch('/live-stats')
                .then(response => response.json())
                .then(data => {{
                    document.getElementById('live-requests').textContent = data.requests_processed;
                    document.getElementById('live-inferences').textContent = data.neural_inferences;
                    document.getElementById('live-uptime').textContent = Math.floor(data.uptime) + 's';
                    document.getElementById('live-clients').textContent = data.active_clients;
                    document.getElementById('live-response-time').textContent = (data.avg_response_time * 1000).toFixed(1) + 'ms';
                    document.getElementById('last-update').textContent = new Date().toLocaleTimeString();
                }})
                .catch(error => console.error('Error fetching stats:', error));
        }}
        
        // –ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        window.onload = function() {{
            startRealTimeUpdates();
            setInterval(fetchLiveStats, 2000); // Fallback –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
        }};
    </script>
</head>
<body>
    <div class="container">
        <h1>üß† Real-Time AnamorphX Neural Server</h1>
        <div class="live-indicator">
            <h2>üî¥ LIVE ‚Ä¢ REAL-TIME NEURAL PROCESSING</h2>
            <p>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: <span class="confidence">{classification['class']}</span> 
            (–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: <span class="confidence">{confidence:.1%}</span>)</p>
            <p>–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: <span id="last-update">—Å–µ–π—á–∞—Å</span></p>
        </div>
        
        <div class="grid">
            <div class="card real-time-data">
                <h3>üî¥ Live Neural Stats</h3>
                <div class="live-metric"><span>–ó–∞–ø—Ä–æ—Å–æ–≤:</span><span id="live-requests">{self.server_instance.stats['requests_processed']}</span></div>
                <div class="live-metric"><span>–ò–Ω—Ñ–µ—Ä–µ–Ω—Å–æ–≤:</span><span id="live-inferences">{self.server_instance.stats['neural_inferences']}</span></div>
                <div class="live-metric"><span>–ö–ª–∏–µ–Ω—Ç–æ–≤:</span><span id="live-clients">{len(self.server_instance.event_manager.clients)}</span></div>
                <div class="live-metric"><span>–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞:</span><span id="live-response-time">{np.mean(self.server_instance.stats['response_times'][-5:]) * 1000:.1f}ms</span></div>
                <div class="live-metric"><span>Uptime:</span><span id="live-uptime">{time.time() - self.server_instance.stats['start_time']:.0f}s</span></div>
            </div>
            
            <div class="card">
                <h3>üß† Neural Model</h3>
                <div class="metric"><span>–¢–∏–ø:</span><span>LSTM Classifier (Real-Time)</span></div>
                <div class="metric"><span>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:</span><span>{sum(p.numel() for p in self.server_instance.neural_processor.model.parameters()):,}</span></div>
                <div class="metric"><span>–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:</span><span>{self.server_instance.neural_processor.device}</span></div>
                <div class="metric"><span>Real-Time:</span><span>‚úÖ –ê–∫—Ç–∏–≤–µ–Ω</span></div>
            </div>
        </div>
        
        <div style="text-align: center; margin-top: 30px;">
            <a href="/api" style="margin: 10px; padding: 10px 20px; background: #4CAF50; color: white; 
               text-decoration: none; border-radius: 5px;">üì° API</a>
            <a href="/neural" style="margin: 10px; padding: 10px 20px; background: #2196F3; color: white; 
               text-decoration: none; border-radius: 5px;">üß† Neural Status</a>
            <a href="/events" style="margin: 10px; padding: 10px 20px; background: #FF5722; color: white; 
               text-decoration: none; border-radius: 5px;">üî¥ Live Events</a>
            <a href="/live-stats" style="margin: 10px; padding: 10px 20px; background: #9C27B0; color: white; 
               text-decoration: none; border-radius: 5px;">üìä Live Stats</a>
        </div>
    </div>
</body>
</html>"""
        return {'status': 200, 'content': html, 'content_type': 'text/html'}
    
    def _handle_neural_api(self, neural_data):
        """API —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        return {
            'status': 200,
            'content': json.dumps(neural_data, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
    
    def _handle_neural_health(self, neural_data):
        """Health check —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"""
        return {
            'status': 200,
            'content': json.dumps(neural_data, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
    
    def _handle_neural_status(self, neural_data):
        """–î–µ—Ç–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        return {
            'status': 200,
            'content': json.dumps(neural_data, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
    
    def _handle_metrics(self):
        """–ú–µ—Ç—Ä–∏–∫–∏ Prometheus-style"""
        stats = self.server_instance.stats
        metrics = f"""# HELP requests_total Total HTTP requests
# TYPE requests_total counter
requests_total {stats['requests_processed']}

# HELP neural_inferences_total Total neural network inferences
# TYPE neural_inferences_total counter
neural_inferences_total {stats['neural_inferences']}

# HELP active_clients_total Active real-time clients
# TYPE active_clients_total gauge
active_clients_total {len(self.server_instance.event_manager.clients)}

# HELP response_time_seconds Response time in seconds
# TYPE response_time_seconds histogram
response_time_seconds_sum {sum(stats['response_times'])}
response_time_seconds_count {len(stats['response_times'])}

# HELP uptime_seconds Server uptime in seconds
# TYPE uptime_seconds counter
uptime_seconds {time.time() - stats['start_time']}
"""
        return {'status': 200, 'content': metrics, 'content_type': 'text/plain'}
    
    def _handle_neural_custom(self, path, neural_data, classification):
        """–ö–∞—Å—Ç–æ–º–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        html = f"""
        <h1>üß† Neural Route: {path}</h1>
        <p><strong>üî¥ REAL-TIME –ù–µ–π—Ä–æ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:</strong> {classification['class']}</p>
        <p><strong>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</strong> {classification['confidence']:.2%}</p>
        <p><strong>–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:</strong> {classification.get('processing_time', 0):.3f}s</p>
        <pre>{json.dumps(neural_data, indent=2, ensure_ascii=False)}</pre>
        """
        return {'status': 200, 'content': html, 'content_type': 'text/html'}
    
    def _send_neural_response(self, response):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Å –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏"""
        self.send_response(response['status'])
        self.send_header('Content-type', response['content_type'] + '; charset=utf-8')
        self.send_header('X-Neural-Engine', 'AnamorphX-PyTorch-RealTime')
        self.send_header('X-Neural-Version', '3.0.0')
        self.send_header('X-RealTime-Enabled', 'true')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        
        content = response['content']
        if isinstance(content, str):
            content = content.encode('utf-8')
        
        self.wfile.write(content)
    
    def log_message(self, format, *args):
        """–ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        pass

def create_realtime_handler(server_instance):
    """–°–æ–∑–¥–∞–Ω–∏–µ real-time –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞"""
    def handler(*args, **kwargs):
        RealtimeNeuralRequestHandler(server_instance, *args, **kwargs)
    return handler

def main():
    """–ó–∞–ø—É—Å–∫ real-time –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
    print("üß† REAL-TIME AnamorphX Neural Web Server")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch
    print(f"üî• PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"‚ö° CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"üéØ GPU: {torch.cuda.get_device_name()}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–∞
    anamorph_file = sys.argv[1] if len(sys.argv) > 1 else "Project/web_server.anamorph"
    neural_server = RealtimeNeuralWebServer(anamorph_file)
    
    host = neural_server.config['host']
    port = neural_server.config['port']
    
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ REAL-TIME –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞...")
    print(f"üì° –•–æ—Å—Ç: {host}")
    print(f"üîå –ü–æ—Ä—Ç: {port}")
    print(f"üß† –ú–æ–¥–µ–ª—å: LSTM Classifier")
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in neural_server.neural_processor.model.parameters()):,}")
    print(f"üî¥ Real-Time: –í–ö–õ–Æ–ß–ï–ù")
    
    try:
        # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
        handler = create_realtime_handler(neural_server)
        httpd = ThreadingHTTPServer((host, port), handler)
        
        print(f"\n‚úÖ REAL-TIME –ù–ï–ô–†–û–ù–ù–´–ô –°–ï–†–í–ï–† –ó–ê–ü–£–©–ï–ù!")
        print(f"üåê URL: http://{host}:{port}")
        print(f"üì° API: http://{host}:{port}/api") 
        print(f"üß† Neural: http://{host}:{port}/neural")
        print(f"üî¥ Live Events: http://{host}:{port}/events")
        print(f"üìä Live Stats: http://{host}:{port}/live-stats")
        print(f"üìä Metrics: http://{host}:{port}/metrics")
        print(f"\nüõë Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        print("=" * 70)
        
        httpd.serve_forever()
        
    except KeyboardInterrupt:
        print(f"\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ real-time –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞...")
        neural_server.event_manager.running = False
        httpd.shutdown()
        neural_server.executor.shutdown(wait=True)
        print(f"‚úÖ –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 