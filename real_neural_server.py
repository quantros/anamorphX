#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß† REAL AnamorphX Neural Web Server
–ù–ê–°–¢–û–Ø–©–ò–ô –Ω–µ–π—Ä–æ–Ω–Ω—ã–π –≤–µ–±-—Å–µ—Ä–≤–µ—Ä —Å PyTorch –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
"""

import sys
import os
import time
import re
import json
import asyncio
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from http.server import HTTPServer, BaseHTTPRequestHandler
from socketserver import ThreadingMixIn
from urllib.parse import urlparse, parse_qs
import threading
import uuid
from datetime import datetime

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ UTF-8
import locale
locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')

class NeuralRequestClassifier(nn.Module):
    """–ù–∞—Å—Ç–æ—è—â–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, vocab_size=1000, embedding_dim=64, hidden_dim=128, num_classes=5):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
        self.fc1 = nn.Linear(hidden_dim, 64)
        self.fc2 = nn.Linear(64, num_classes)
        self.dropout = nn.Dropout(0.3)
        
    def forward(self, x):
        embedded = self.embedding(x)
        lstm_out, (hidden, _) = self.lstm(embedded)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π
        output = self.fc1(hidden[-1])
        output = F.relu(output)
        output = self.dropout(output)
        output = self.fc2(output)
        return F.softmax(output, dim=1)

class RequestProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = NeuralRequestClassifier()
        self.model.to(self.device)
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        self.vocab = self._build_vocab()
        self.request_classes = ['api', 'health', 'neural', 'admin', 'custom']
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –æ–±—É—á–µ–Ω–∏–µ)
        self._initialize_weights()
        
        print(f"üß† Neural model loaded on {self.device}")
        print(f"üìä Model parameters: {sum(p.numel() for p in self.model.parameters()):,}")
    
    def _build_vocab(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        common_words = [
            'get', 'post', 'api', 'health', 'neural', 'admin', 'status', 'info',
            'data', 'request', 'response', 'server', 'network', 'model', 'predict',
            'train', 'test', 'validate', 'metric', 'loss', 'accuracy', 'error'
        ]
        return {word: idx + 1 for idx, word in enumerate(common_words)}
    
    def _initialize_weights(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏"""
        for module in self.model.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                nn.init.zeros_(module.bias)
            elif isinstance(module, nn.LSTM):
                for name, param in module.named_parameters():
                    if 'weight' in name:
                        nn.init.xavier_uniform_(param)
                    elif 'bias' in name:
                        nn.init.zeros_(param)
    
    def encode_request(self, path, method='GET', headers=None):
        """–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        text = f"{method.lower()} {path.lower()}"
        if headers:
            text += " " + " ".join(headers.keys()).lower()
        
        tokens = []
        for word in text.split():
            if word in self.vocab:
                tokens.append(self.vocab[word])
            else:
                tokens.append(0)  # UNK token
        
        # –ü–∞–¥–¥–∏–Ω–≥ –¥–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã
        max_len = 20
        if len(tokens) > max_len:
            tokens = tokens[:max_len]
        else:
            tokens.extend([0] * (max_len - len(tokens)))
        
        return torch.tensor([tokens], dtype=torch.long)
    
    def classify_request(self, path, method='GET', headers=None):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é"""
        with torch.no_grad():
            encoded = self.encode_request(path, method, headers)
            encoded = encoded.to(self.device)
            
            # –ü—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
            output = self.model(encoded)
            predicted_class = torch.argmax(output, dim=1).item()
            confidence = torch.max(output).item()
            
            return {
                'class': self.request_classes[predicted_class],
                'confidence': float(confidence),
                'raw_output': output.cpu().numpy().tolist()[0]
            }

class NeuralResponseGenerator(nn.Module):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
    
    def __init__(self, input_dim=64, hidden_dim=128, output_dim=256):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, output_dim),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.net(x)

class ThreadingHTTPServer(ThreadingMixIn, HTTPServer):
    """–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π HTTP —Å–µ—Ä–≤–µ—Ä"""
    daemon_threads = True

class RealNeuralWebServer:
    """–†–ï–ê–õ–¨–ù–´–ô –Ω–µ–π—Ä–æ–Ω–Ω—ã–π –≤–µ–±-—Å–µ—Ä–≤–µ—Ä"""
    
    def __init__(self, anamorph_file="Project/web_server.anamorph"):
        self.anamorph_file = anamorph_file
        self.config = {}
        self.neural_processor = RequestProcessor()
        self.response_generator = NeuralResponseGenerator()
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'requests_processed': 0,
            'neural_inferences': 0,
            'start_time': time.time(),
            'request_types': {},
            'response_times': []
        }
        
        self._load_config()
    
    def _load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(self.anamorph_file, 'r', encoding='utf-8') as f:
                code = f.read()
            
            self.config = {
                'host': 'localhost',
                'port': 8080,
                'neural_processing': True,
                'async_processing': True
            }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Ä—Ç–∞
            port_match = re.search(r'port[:\s]*(\d+)', code, re.IGNORECASE)
            if port_match:
                self.config['port'] = int(port_match.group(1))
            
            print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.anamorph_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {e}")
    
    def process_request_neural(self, path, method, headers, body=None):
        """–ù–µ–π—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"""
        start_time = time.time()
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
        classification = self.neural_processor.classify_request(path, method, headers)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        response_data = self._generate_neural_response(classification, path, body)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        processing_time = time.time() - start_time
        self.stats['neural_inferences'] += 1
        self.stats['response_times'].append(processing_time)
        
        return response_data, classification, processing_time
    
    def _generate_neural_response(self, classification, path, body):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        request_class = classification['class']
        confidence = classification['confidence']
        
        base_response = {
            'timestamp': datetime.now().isoformat(),
            'neural_classification': classification,
            'processing_method': 'neural_network',
            'confidence': confidence,
            'path': path
        }
        
        if request_class == 'api':
            base_response.update({
                'server': 'AnamorphX Real Neural Server',
                'version': '2.0.0',
                'neural_engine': 'PyTorch',
                'model_parameters': sum(p.numel() for p in self.neural_processor.model.parameters()),
                'device': str(self.neural_processor.device),
                'features': ['real_neural_processing', 'pytorch_integration', 'async_inference']
            })
        
        elif request_class == 'health':
            uptime = time.time() - self.stats['start_time']
            base_response.update({
                'status': 'neural_healthy',
                'uptime_seconds': uptime,
                'model_status': 'active',
                'inference_count': self.stats['neural_inferences'],
                'avg_response_time': np.mean(self.stats['response_times'][-100:]) if self.stats['response_times'] else 0
            })
        
        elif request_class == 'neural':
            base_response.update({
                'model_info': {
                    'type': 'LSTM Classifier',
                    'parameters': sum(p.numel() for p in self.neural_processor.model.parameters()),
                    'device': str(self.neural_processor.device),
                    'vocab_size': len(self.neural_processor.vocab),
                    'classes': self.neural_processor.request_classes
                },
                'recent_inferences': self.stats['neural_inferences'],
                'performance': {
                    'avg_inference_time': np.mean(self.stats['response_times'][-50:]) if self.stats['response_times'] else 0,
                    'total_requests': self.stats['requests_processed']
                }
            })
        
        return base_response

class RealNeuralRequestHandler(BaseHTTPRequestHandler):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å —Ä–µ–∞–ª—å–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é"""
    
    def __init__(self, server_instance, *args, **kwargs):
        self.server_instance = server_instance
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        """GET –∑–∞–ø—Ä–æ—Å—ã —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        start_time = time.time()
        parsed_path = urlparse(self.path)
        path = parsed_path.path
        
        # –ù–µ–π—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        neural_data, classification, processing_time = self.server_instance.process_request_neural(
            path, 'GET', dict(self.headers)
        )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        if path == '/':
            response = self._handle_neural_index(neural_data, classification)
        elif path == '/api':
            response = self._handle_neural_api(neural_data)
        elif path == '/health':
            response = self._handle_neural_health(neural_data)
        elif path == '/neural':
            response = self._handle_neural_status(neural_data)
        elif path == '/metrics':
            response = self._handle_metrics()
        else:
            response = self._handle_neural_custom(path, neural_data, classification)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total_time = time.time() - start_time
        self.server_instance.stats['requests_processed'] += 1
        self.server_instance.stats['request_types'][path] = self.server_instance.stats['request_types'].get(path, 0) + 1
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        print(f"üß† Neural GET {path} | Class: {classification['class']} | Confidence: {classification['confidence']:.3f} | Time: {total_time:.3f}s")
        
        self._send_neural_response(response)
    
    def do_POST(self):
        """POST –∑–∞–ø—Ä–æ—Å—ã —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        parsed_path = urlparse(self.path)
        path = parsed_path.path
        
        # –ß—Ç–µ–Ω–∏–µ —Ç–µ–ª–∞ –∑–∞–ø—Ä–æ—Å–∞
        content_length = int(self.headers.get('Content-Length', 0))
        body = self.rfile.read(content_length) if content_length > 0 else b''
        
        # –ù–µ–π—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        neural_data, classification, processing_time = self.server_instance.process_request_neural(
            path, 'POST', dict(self.headers), body
        )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ POST –¥–∞–Ω–Ω—ã—Ö
        try:
            if body:
                json_data = json.loads(body.decode('utf-8'))
                neural_data['received_data'] = json_data
        except:
            neural_data['received_data'] = {'raw': body.decode('utf-8', errors='ignore')}
        
        response = {
            'status': 200,
            'content': json.dumps(neural_data, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
        
        print(f"üß† Neural POST {path} | Class: {classification['class']} | Data: {len(body)} bytes")
        self._send_neural_response(response)
    
    def _handle_neural_index(self, neural_data, classification):
        """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        confidence = classification['confidence']
        html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <title>üß† Real AnamorphX Neural Server</title>
    <style>
        body {{ font-family: 'SF Pro Display', system-ui; margin: 0; padding: 20px; 
               background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
        .container {{ background: rgba(255,255,255,0.95); padding: 40px; border-radius: 20px; 
                     box-shadow: 0 25px 50px rgba(0,0,0,0.15); }}
        h1 {{ color: #2E7D32; text-align: center; margin-bottom: 30px; }}
        .neural-status {{ background: linear-gradient(45deg, #4CAF50, #81C784); color: white; 
                          padding: 20px; border-radius: 15px; text-align: center; margin: 20px 0; }}
        .grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        .card {{ background: white; padding: 25px; border-radius: 15px; box-shadow: 0 8px 25px rgba(0,0,0,0.1); }}
        .metric {{ background: #e3f2fd; padding: 12px; margin: 8px 0; border-radius: 8px; 
                  display: flex; justify-content: space-between; }}
        .confidence {{ font-size: 1.2em; font-weight: bold; 
                      color: {'#4CAF50' if confidence > 0.7 else '#FF9800' if confidence > 0.4 else '#f44336'}; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üß† Real AnamorphX Neural Server</h1>
        <div class="neural-status">
            <h2>‚ö° –ù–ê–°–¢–û–Ø–©–ê–Ø –ù–ï–ô–†–û–ù–ù–ê–Ø –°–ï–¢–¨ –ê–ö–¢–ò–í–ù–ê</h2>
            <p>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: <span class="confidence">{classification['class']}</span> 
            (–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: <span class="confidence">{confidence:.1%}</span>)</p>
        </div>
        
        <div class="grid">
            <div class="card">
                <h3>üß† Neural Model</h3>
                <div class="metric"><span>–¢–∏–ø:</span><span>LSTM Classifier</span></div>
                <div class="metric"><span>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:</span><span>{sum(p.numel() for p in self.server_instance.neural_processor.model.parameters()):,}</span></div>
                <div class="metric"><span>–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:</span><span>{self.server_instance.neural_processor.device}</span></div>
                <div class="metric"><span>–ò–Ω—Ñ–µ—Ä–µ–Ω—Å–æ–≤:</span><span>{self.server_instance.stats['neural_inferences']}</span></div>
            </div>
            
            <div class="card">
                <h3>üìä Performance</h3>
                <div class="metric"><span>–ó–∞–ø—Ä–æ—Å–æ–≤:</span><span>{self.server_instance.stats['requests_processed']}</span></div>
                <div class="metric"><span>–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è:</span><span>{np.mean(self.server_instance.stats['response_times'][-10:]):.3f}s</span></div>
                <div class="metric"><span>Uptime:</span><span>{time.time() - self.server_instance.stats['start_time']:.0f}s</span></div>
            </div>
        </div>
        
        <div style="text-align: center; margin-top: 30px;">
            <a href="/api" style="margin: 10px; padding: 10px 20px; background: #4CAF50; color: white; 
               text-decoration: none; border-radius: 5px;">üì° API</a>
            <a href="/neural" style="margin: 10px; padding: 10px 20px; background: #2196F3; color: white; 
               text-decoration: none; border-radius: 5px;">üß† Neural Status</a>
            <a href="/metrics" style="margin: 10px; padding: 10px 20px; background: #FF9800; color: white; 
               text-decoration: none; border-radius: 5px;">üìä Metrics</a>
        </div>
    </div>
</body>
</html>"""
        return {'status': 200, 'content': html, 'content_type': 'text/html'}
    
    def _handle_neural_api(self, neural_data):
        """API —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        return {
            'status': 200,
            'content': json.dumps(neural_data, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
    
    def _handle_neural_health(self, neural_data):
        """Health check —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"""
        return {
            'status': 200,
            'content': json.dumps(neural_data, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
    
    def _handle_neural_status(self, neural_data):
        """–î–µ—Ç–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        return {
            'status': 200,
            'content': json.dumps(neural_data, indent=2, ensure_ascii=False),
            'content_type': 'application/json'
        }
    
    def _handle_metrics(self):
        """–ú–µ—Ç—Ä–∏–∫–∏ Prometheus-style"""
        stats = self.server_instance.stats
        metrics = f"""# HELP requests_total Total HTTP requests
# TYPE requests_total counter
requests_total {stats['requests_processed']}

# HELP neural_inferences_total Total neural network inferences
# TYPE neural_inferences_total counter
neural_inferences_total {stats['neural_inferences']}

# HELP response_time_seconds Response time in seconds
# TYPE response_time_seconds histogram
response_time_seconds_sum {sum(stats['response_times'])}
response_time_seconds_count {len(stats['response_times'])}

# HELP uptime_seconds Server uptime in seconds
# TYPE uptime_seconds counter
uptime_seconds {time.time() - stats['start_time']}
"""
        return {'status': 200, 'content': metrics, 'content_type': 'text/plain'}
    
    def _handle_neural_custom(self, path, neural_data, classification):
        """–ö–∞—Å—Ç–æ–º–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        html = f"""
        <h1>üß† Neural Route: {path}</h1>
        <p><strong>–ù–µ–π—Ä–æ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:</strong> {classification['class']}</p>
        <p><strong>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</strong> {classification['confidence']:.2%}</p>
        <pre>{json.dumps(neural_data, indent=2, ensure_ascii=False)}</pre>
        """
        return {'status': 200, 'content': html, 'content_type': 'text/html'}
    
    def _send_neural_response(self, response):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Å –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏"""
        self.send_response(response['status'])
        self.send_header('Content-type', response['content_type'] + '; charset=utf-8')
        self.send_header('X-Neural-Engine', 'AnamorphX-PyTorch')
        self.send_header('X-Neural-Version', '2.0.0')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        
        content = response['content']
        if isinstance(content, str):
            content = content.encode('utf-8')
        
        self.wfile.write(content)
    
    def log_message(self, format, *args):
        """–ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        pass

def create_neural_handler(server_instance):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞"""
    def handler(*args, **kwargs):
        RealNeuralRequestHandler(server_instance, *args, **kwargs)
    return handler

def main():
    """–ó–∞–ø—É—Å–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
    print("üß† REAL AnamorphX Neural Web Server")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch
    print(f"üî• PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"‚ö° CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"üéØ GPU: {torch.cuda.get_device_name()}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–∞
    anamorph_file = sys.argv[1] if len(sys.argv) > 1 else "Project/web_server.anamorph"
    neural_server = RealNeuralWebServer(anamorph_file)
    
    host = neural_server.config['host']
    port = neural_server.config['port']
    
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞...")
    print(f"üì° –•–æ—Å—Ç: {host}")
    print(f"üîå –ü–æ—Ä—Ç: {port}")
    print(f"üß† –ú–æ–¥–µ–ª—å: LSTM Classifier")
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in neural_server.neural_processor.model.parameters()):,}")
    
    try:
        # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
        handler = create_neural_handler(neural_server)
        httpd = ThreadingHTTPServer((host, port), handler)
        
        print(f"\n‚úÖ –†–ï–ê–õ–¨–ù–´–ô –ù–ï–ô–†–û–ù–ù–´–ô –°–ï–†–í–ï–† –ó–ê–ü–£–©–ï–ù!")
        print(f"üåê URL: http://{host}:{port}")
        print(f"üì° API: http://{host}:{port}/api") 
        print(f"üß† Neural: http://{host}:{port}/neural")
        print(f"üìä Metrics: http://{host}:{port}/metrics")
        print(f"\nüõë Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        print("=" * 60)
        
        httpd.serve_forever()
        
    except KeyboardInterrupt:
        print(f"\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞...")
        httpd.shutdown()
        neural_server.executor.shutdown(wait=True)
        print(f"‚úÖ –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 