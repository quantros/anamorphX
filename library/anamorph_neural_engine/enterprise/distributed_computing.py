"""
üåê Distributed Computing –¥–ª—è AnamorphX Enterprise
–°–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
"""

import asyncio
import aiohttp
import json
import time
import uuid
import hashlib
import threading
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
import logging
from concurrent.futures import ThreadPoolExecutor
import socket
import psutil

class NodeType(Enum):
    """–¢–∏–ø—ã —É–∑–ª–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ"""
    MASTER = "master"
    WORKER = "worker"
    BACKUP = "backup"

class TaskStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã –∑–∞–¥–∞—á"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class ClusterNode:
    """–£–∑–µ–ª –∫–ª–∞—Å—Ç–µ—Ä–∞"""
    node_id: str
    host: str
    port: int
    node_type: NodeType
    status: str = "active"
    last_heartbeat: float = 0
    cpu_count: int = 0
    memory_gb: float = 0
    gpu_count: int = 0
    current_load: float = 0
    capabilities: List[str] = None
    
    def __post_init__(self):
        if self.capabilities is None:
            self.capabilities = []

@dataclass
class DistributedTask:
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞"""
    task_id: str
    task_type: str
    payload: Dict[str, Any]
    priority: int = 1
    requirements: Dict[str, Any] = None
    created_at: float = 0
    started_at: float = 0
    completed_at: float = 0
    status: TaskStatus = TaskStatus.PENDING
    assigned_node: Optional[str] = None
    result: Optional[Any] = None
    error: Optional[str] = None
    
    def __post_init__(self):
        if self.requirements is None:
            self.requirements = {}
        if self.created_at == 0:
            self.created_at = time.time()

class LoadBalancer:
    """–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫ –Ω–∞–≥—Ä—É–∑–∫–∏"""
    
    def __init__(self, strategy: str = "round_robin"):
        self.strategy = strategy
        self.current_index = 0
        
    def select_node(self, nodes: List[ClusterNode], 
                   requirements: Dict[str, Any] = None) -> Optional[ClusterNode]:
        """–í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —É–∑–ª–∞"""
        if not nodes:
            return None
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–∑–ª–æ–≤ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
        suitable_nodes = self._filter_nodes(nodes, requirements or {})
        
        if not suitable_nodes:
            return None
        
        if self.strategy == "round_robin":
            return self._round_robin_selection(suitable_nodes)
        elif self.strategy == "least_loaded":
            return self._least_loaded_selection(suitable_nodes)
        elif self.strategy == "random":
            import random
            return random.choice(suitable_nodes)
        else:
            return suitable_nodes[0]
    
    def _filter_nodes(self, nodes: List[ClusterNode], 
                     requirements: Dict[str, Any]) -> List[ClusterNode]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–∑–ª–æ–≤ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º"""
        filtered = []
        
        for node in nodes:
            if node.status != "active":
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
            if requirements.get('min_memory', 0) > node.memory_gb:
                continue
            if requirements.get('min_cpu', 0) > node.cpu_count:
                continue
            if requirements.get('gpu_required', False) and node.gpu_count == 0:
                continue
            if requirements.get('max_load', 1.0) < node.current_load:
                continue
            
            required_capabilities = requirements.get('capabilities', [])
            if not all(cap in node.capabilities for cap in required_capabilities):
                continue
            
            filtered.append(node)
        
        return filtered
    
    def _round_robin_selection(self, nodes: List[ClusterNode]) -> ClusterNode:
        """Round-robin –≤—ã–±–æ—Ä"""
        node = nodes[self.current_index % len(nodes)]
        self.current_index += 1
        return node
    
    def _least_loaded_selection(self, nodes: List[ClusterNode]) -> ClusterNode:
        """–í—ã–±–æ—Ä –Ω–∞–∏–º–µ–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —É–∑–ª–∞"""
        return min(nodes, key=lambda n: n.current_load)

class DistributedTaskManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á"""
    
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.tasks: Dict[str, DistributedTask] = {}
        self.task_queue = asyncio.Queue()
        self.result_callbacks: Dict[str, Callable] = {}
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.logger = logging.getLogger(__name__)
        
    async def submit_task(self, task_type: str, payload: Dict[str, Any],
                         priority: int = 1, requirements: Dict[str, Any] = None) -> str:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥—å"""
        task_id = str(uuid.uuid4())
        
        task = DistributedTask(
            task_id=task_id,
            task_type=task_type,
            payload=payload,
            priority=priority,
            requirements=requirements or {}
        )
        
        self.tasks[task_id] = task
        await self.task_queue.put(task)
        
        self.logger.info(f"üìã –ó–∞–¥–∞—á–∞ {task_id} –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å")
        return task_id
    
    async def execute_task(self, task: DistributedTask) -> Any:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        task.status = TaskStatus.RUNNING
        task.started_at = time.time()
        
        try:
            self.logger.info(f"üöÄ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ {task.task_id}")
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
            if task.task_type == "neural_training":
                result = await self._execute_neural_training(task)
            elif task.task_type == "neural_inference":
                result = await self._execute_neural_inference(task)
            elif task.task_type == "data_processing":
                result = await self._execute_data_processing(task)
            elif task.task_type == "model_optimization":
                result = await self._execute_model_optimization(task)
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task.task_type}")
            
            task.result = result
            task.status = TaskStatus.COMPLETED
            task.completed_at = time.time()
            
            self.logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task.task_id} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
            return result
            
        except Exception as e:
            task.error = str(e)
            task.status = TaskStatus.FAILED
            task.completed_at = time.time()
            
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ {task.task_id}: {e}")
            raise
    
    async def _execute_neural_training(self, task: DistributedTask) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        payload = task.payload
        model_config = payload.get('model_config', {})
        training_data = payload.get('training_data', [])
        epochs = payload.get('epochs', 10)
        
        # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        await asyncio.sleep(2)  # –ò–º–∏—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è
        
        return {
            'model_id': f"model_{task.task_id[:8]}",
            'epochs_completed': epochs,
            'final_loss': 0.001,
            'accuracy': 0.95,
            'training_time': 2.0
        }
    
    async def _execute_neural_inference(self, task: DistributedTask) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"""
        payload = task.payload
        model_id = payload.get('model_id')
        input_data = payload.get('input_data')
        
        # –°–∏–º—É–ª—è—Ü–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        await asyncio.sleep(0.1)
        
        return {
            'predictions': [0.8, 0.2],
            'confidence': 0.8,
            'processing_time': 0.1
        }
    
    async def _execute_data_processing(self, task: DistributedTask) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
        payload = task.payload
        data = payload.get('data', [])
        operation = payload.get('operation', 'transform')
        
        # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        await asyncio.sleep(1)
        
        return {
            'processed_items': len(data),
            'operation': operation,
            'output_size': len(data) * 2
        }
    
    async def _execute_model_optimization(self, task: DistributedTask) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
        payload = task.payload
        model_id = payload.get('model_id')
        optimization_type = payload.get('optimization_type', 'quantization')
        
        # –°–∏–º—É–ª—è—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        await asyncio.sleep(3)
        
        return {
            'original_size_mb': 100,
            'optimized_size_mb': 25,
            'compression_ratio': 4.0,
            'optimization_type': optimization_type
        }
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏"""
        if task_id not in self.tasks:
            return None
        
        task = self.tasks[task_id]
        return {
            'task_id': task.task_id,
            'status': task.status.value,
            'progress': self._calculate_progress(task),
            'created_at': task.created_at,
            'started_at': task.started_at,
            'completed_at': task.completed_at,
            'result': task.result,
            'error': task.error
        }
    
    def _calculate_progress(self, task: DistributedTask) -> float:
        """–†–∞—Å—á–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏"""
        if task.status == TaskStatus.PENDING:
            return 0.0
        elif task.status == TaskStatus.RUNNING:
            # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            if task.started_at > 0:
                elapsed = time.time() - task.started_at
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∑–∞–¥–∞—á–∞ –∑–∞–π–º–µ—Ç –æ—Ç 1 –¥–æ 10 —Å–µ–∫—É–Ω–¥
                estimated_duration = 5.0
                return min(elapsed / estimated_duration, 0.99)
            return 0.1
        elif task.status in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED]:
            return 1.0
        return 0.0

class ClusterManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞"""
    
    def __init__(self, node_id: str, node_type: NodeType = NodeType.WORKER,
                 host: str = "localhost", port: int = 8080):
        self.node_id = node_id
        self.node_type = node_type
        self.host = host
        self.port = port
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞
        self.nodes: Dict[str, ClusterNode] = {}
        self.master_node: Optional[str] = None
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.load_balancer = LoadBalancer("least_loaded")
        self.task_manager = DistributedTaskManager(node_id)
        
        # –°–µ—Ç–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.session: Optional[aiohttp.ClientSession] = None
        self.heartbeat_interval = 30  # —Å–µ–∫—É–Ω–¥
        self.heartbeat_task: Optional[asyncio.Task] = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'tasks_completed': 0,
            'tasks_failed': 0,
            'total_processing_time': 0.0,
            'uptime_start': time.time()
        }
        
        self.logger = logging.getLogger(__name__)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–º —É–∑–ª–µ
        self._create_current_node()
    
    def _create_current_node(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–º —É–∑–ª–µ"""
        self.current_node = ClusterNode(
            node_id=self.node_id,
            host=self.host,
            port=self.port,
            node_type=self.node_type,
            cpu_count=psutil.cpu_count(),
            memory_gb=psutil.virtual_memory().total / (1024**3),
            gpu_count=0,  # –£–ø—Ä–æ—â–µ–Ω–æ
            capabilities=["neural_training", "neural_inference", "data_processing"]
        )
    
    async def start(self):
        """–ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ —É–∑–ª–∞"""
        self.session = aiohttp.ClientSession()
        
        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
        if self.node_type == NodeType.WORKER:
            await self._register_with_master()
        
        # –ó–∞–ø—É—Å–∫ heartbeat
        self.heartbeat_task = asyncio.create_task(self._heartbeat_loop())
        
        # –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á
        asyncio.create_task(self._task_processing_loop())
        
        print(f"üåê –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π —É–∑–µ–ª {self.node_id} –∑–∞–ø—É—â–µ–Ω")
        print(f"   üîß –¢–∏–ø: {self.node_type.value}")
        print(f"   üñ•Ô∏è CPU: {self.current_node.cpu_count} cores")
        print(f"   üíæ Memory: {self.current_node.memory_gb:.1f} GB")
    
    async def _register_with_master(self):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è worker —É–∑–ª–∞ –≤ master"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –ø–æ–∏—Å–∫ master —É–∑–ª–∞
        # –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é
        pass
    
    async def _heartbeat_loop(self):
        """–¶–∏–∫–ª –æ—Ç–ø—Ä–∞–≤–∫–∏ heartbeat"""
        while True:
            try:
                await self._send_heartbeat()
                await asyncio.sleep(self.heartbeat_interval)
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ heartbeat: {e}")
                await asyncio.sleep(5)
    
    async def _send_heartbeat(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ heartbeat"""
        self.current_node.last_heartbeat = time.time()
        self.current_node.current_load = self._calculate_current_load()
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ä–µ–µ—Å—Ç—Ä–µ
        self.nodes[self.node_id] = self.current_node
        
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∞ –±—ã –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ master
        self.logger.debug(f"üíì Heartbeat: load={self.current_node.current_load:.2f}")
    
    def _calculate_current_load(self) -> float:
        """–†–∞—Å—á–µ—Ç —Ç–µ–∫—É—â–µ–π –Ω–∞–≥—Ä—É–∑–∫–∏ —É–∑–ª–∞"""
        cpu_percent = psutil.cpu_percent()
        memory_percent = psutil.virtual_memory().percent
        
        # –ü—Ä–æ—Å—Ç–∞—è —Ñ–æ—Ä–º—É–ª–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
        return (cpu_percent + memory_percent) / 200.0
    
    async def _task_processing_loop(self):
        """–¶–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á"""
        while True:
            try:
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                task = await self.task_manager.task_queue.get()
                
                # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏
                start_time = time.time()
                try:
                    result = await self.task_manager.execute_task(task)
                    self.stats['tasks_completed'] += 1
                except Exception as e:
                    self.stats['tasks_failed'] += 1
                    self.logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {e}")
                
                processing_time = time.time() - start_time
                self.stats['total_processing_time'] += processing_time
                
                # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
                self.task_manager.task_queue.task_done()
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á: {e}")
                await asyncio.sleep(1)
    
    async def submit_distributed_task(self, task_type: str, payload: Dict[str, Any],
                                    requirements: Dict[str, Any] = None) -> str:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏"""
        # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —É–∑–ª–∞
        available_nodes = [node for node in self.nodes.values() 
                          if node.status == "active" and node.node_type == NodeType.WORKER]
        
        target_node = self.load_balancer.select_node(available_nodes, requirements)
        
        if not target_node:
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–∞ —Ç–µ–∫—É—â–µ–º —É–∑–ª–µ
            return await self.task_manager.submit_task(task_type, payload, 
                                                     requirements=requirements)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á–∏ –Ω–∞ –¥—Ä—É–≥–æ–π —É–∑–µ–ª
        task_id = await self._send_task_to_node(target_node, task_type, payload, requirements)
        return task_id
    
    async def _send_task_to_node(self, node: ClusterNode, task_type: str,
                               payload: Dict[str, Any], requirements: Dict[str, Any]) -> str:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á–∏ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —É–∑–µ–ª"""
        if node.node_id == self.node_id:
            # –õ–æ–∫–∞–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            return await self.task_manager.submit_task(task_type, payload, 
                                                     requirements=requirements)
        
        # –£–¥–∞–ª–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ (—á–µ—Ä–µ–∑ HTTP API)
        try:
            task_data = {
                'task_type': task_type,
                'payload': payload,
                'requirements': requirements
            }
            
            url = f"http://{node.host}:{node.port}/api/tasks/submit"
            async with self.session.post(url, json=task_data) as response:
                result = await response.json()
                return result.get('task_id')
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–¥–∞—á–∏ –Ω–∞ —É–∑–µ–ª {node.node_id}: {e}")
            # Fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            return await self.task_manager.submit_task(task_type, payload,
                                                     requirements=requirements)
    
    def add_node(self, node: ClusterNode):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–∞ –≤ –∫–ª–∞—Å—Ç–µ—Ä"""
        self.nodes[node.node_id] = node
        print(f"‚ûï –£–∑–µ–ª {node.node_id} –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∫–ª–∞—Å—Ç–µ—Ä")
    
    def remove_node(self, node_id: str):
        """–£–¥–∞–ª–µ–Ω–∏–µ —É–∑–ª–∞ –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        if node_id in self.nodes:
            del self.nodes[node_id]
            print(f"‚ûñ –£–∑–µ–ª {node_id} —É–¥–∞–ª–µ–Ω –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞")
    
    def get_cluster_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        active_nodes = [n for n in self.nodes.values() if n.status == "active"]
        
        total_cpu = sum(node.cpu_count for node in active_nodes)
        total_memory = sum(node.memory_gb for node in active_nodes)
        avg_load = sum(node.current_load for node in active_nodes) / len(active_nodes) if active_nodes else 0
        
        return {
            'cluster_size': len(self.nodes),
            'active_nodes': len(active_nodes),
            'total_cpu_cores': total_cpu,
            'total_memory_gb': total_memory,
            'average_load': avg_load,
            'master_node': self.master_node,
            'current_node': self.node_id,
            'stats': self.stats
        }
    
    def get_node_info(self, node_id: str = None) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É–∑–ª–µ"""
        if node_id is None:
            node_id = self.node_id
        
        if node_id not in self.nodes:
            return None
        
        node = self.nodes[node_id]
        return asdict(node)
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ —É–∑–ª–∞"""
        if self.heartbeat_task:
            self.heartbeat_task.cancel()
        
        if self.session:
            await self.session.close()
        
        self.task_manager.executor.shutdown(wait=True)
        
        print(f"üõë –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π —É–∑–µ–ª {self.node_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

class DistributedNeuralNetwork:
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å"""
    
    def __init__(self, cluster_manager: ClusterManager):
        self.cluster_manager = cluster_manager
        self.model_shards: Dict[str, List[str]] = {}  # model_id -> list of node_ids
        self.logger = logging.getLogger(__name__)
    
    async def train_distributed_model(self, model_config: Dict[str, Any],
                                    training_data: List[Any]) -> str:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        model_id = f"distributed_model_{uuid.uuid4().hex[:8]}"
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —É–∑–ª–∞–º–∏
        data_shards = self._shard_data(training_data)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–Ω—ã–µ —É–∑–ª—ã
        training_tasks = []
        for shard_data in data_shards:
            task_id = await self.cluster_manager.submit_distributed_task(
                "neural_training",
                {
                    'model_config': model_config,
                    'training_data': shard_data,
                    'model_id': model_id
                },
                requirements={'min_memory': 2.0, 'capabilities': ['neural_training']}
            )
            training_tasks.append(task_id)
        
        # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        await self._wait_for_tasks(training_tasks)
        
        print(f"üß† –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å {model_id} –æ–±—É—á–µ–Ω–∞ –Ω–∞ {len(data_shards)} —É–∑–ª–∞—Ö")
        return model_id
    
    def _shard_data(self, data: List[Any], max_shards: int = 4) -> List[List[Any]]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —á–∞—Å—Ç–∏"""
        if len(data) <= max_shards:
            return [[item] for item in data]
        
        shard_size = len(data) // max_shards
        shards = []
        
        for i in range(max_shards):
            start_idx = i * shard_size
            end_idx = start_idx + shard_size if i < max_shards - 1 else len(data)
            shards.append(data[start_idx:end_idx])
        
        return shards
    
    async def _wait_for_tasks(self, task_ids: List[str], timeout: float = 300):
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á"""
        start_time = time.time()
        
        while True:
            completed_tasks = 0
            
            for task_id in task_ids:
                status = self.cluster_manager.task_manager.get_task_status(task_id)
                if status and status['status'] in ['completed', 'failed']:
                    completed_tasks += 1
            
            if completed_tasks == len(task_ids):
                break
            
            if time.time() - start_time > timeout:
                raise TimeoutError(f"–ó–∞–¥–∞—á–∏ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –∑–∞ {timeout} —Å–µ–∫—É–Ω–¥")
            
            await asyncio.sleep(1)
    
    async def parallel_inference(self, model_id: str, input_batch: List[Any]) -> List[Dict[str, Any]]:
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å"""
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –±–∞—Ç—á–∞ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏
        batch_shards = self._shard_data(input_batch)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        inference_tasks = []
        for shard in batch_shards:
            task_id = await self.cluster_manager.submit_distributed_task(
                "neural_inference",
                {
                    'model_id': model_id,
                    'input_data': shard
                },
                requirements={'capabilities': ['neural_inference']}
            )
            inference_tasks.append(task_id)
        
        # –û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        await self._wait_for_tasks(inference_tasks)
        
        # –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results = []
        for task_id in inference_tasks:
            status = self.cluster_manager.task_manager.get_task_status(task_id)
            if status and status['result']:
                results.extend(status['result'].get('predictions', []))
        
        return results 